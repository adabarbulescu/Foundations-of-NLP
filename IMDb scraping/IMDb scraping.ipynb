{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IMDb_chart_page(category):\n",
    "    return requests.get(f\"https://www.imdb.com/chart/{category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(response):\n",
    "    return BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge(dict1, dict2):\n",
    "    res = {**dict1, **dict2}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the IMDb Top 250 movies page\n",
    "response = get_IMDb_chart_page('top/')\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = parse_html(response)\n",
    "\n",
    "# Find all the movie names and movie links in the page\n",
    "movie_elements = soup.find_all('td', class_='titleColumn')\n",
    "\n",
    "# Initialize an empty list to store the review data\n",
    "review_data = []\n",
    "links = []\n",
    "\n",
    "# Loop through the title_columns and extract the film names and links\n",
    "for movie in movie_elements:\n",
    "    # Find the film name\n",
    "    movie_name = movie.find_all('a')[-1].text\n",
    "\n",
    "    # Find the link to the review\n",
    "    review_link = 'https://imdb.com' + \\\n",
    "        movie.find('a')['href'] + \\\n",
    "            'reviews/'\n",
    "            \n",
    "    rating = soup.find(class_= \"ratingColumn imdbRating\").text\n",
    "        \n",
    "    rating = rating.strip('\\n')\n",
    "    rating = float(rating)\n",
    "    reviewdict1 = { 'rating': rating,}\n",
    "    \n",
    "        # Print the film name and review link\n",
    "    # print(f'Here is the review page for \"{movie_name}\": \\n {review_link}')\n",
    "    links.append(review_link)\n",
    "    \n",
    "for review in links:\n",
    "    # Make a request to the review webpage \n",
    "    review_page_response = requests.get(f'{review}')\n",
    "    \n",
    "    # review_page_response = requests.get(f'https://www.imdb.com{review_link}')\n",
    "    \n",
    "    #parse the HTML content\n",
    "    review_soup = parse_html(review_page_response)\n",
    "    # Find all the review elements\n",
    "    review_elements = review_soup.find_all(class_='review-container')\n",
    "\n",
    "    # Loop through the review elements and extract the review data\n",
    "    for element in review_elements:\n",
    "        # Find the title of the review\n",
    "        review_title = element.find(class_='title').text\n",
    "\n",
    "        # Find the text of the review\n",
    "        review_text = element.find(class_='text').text\n",
    "\n",
    "        # # Find the rating of the review\n",
    "        # rating = element.find(class_='rating-other-user-rating')[0].get_text().strip()\n",
    "\n",
    "        \n",
    "        #Find the date of the review\n",
    "        review_date = element.find(class_= 'review-date').text\n",
    "\n",
    "        # Find the user who wrote the review\n",
    "        review_user = element.find(class_='display-name-link').text\n",
    "\n",
    "        # Store the review data in a dictionary\n",
    "        reviewdict = {\n",
    "            'title': review_title,\n",
    "            'text': review_text,\n",
    "            # 'rating': rating,\n",
    "            'date': review_date,\n",
    "            'user': review_user\n",
    "        }\n",
    "        \n",
    "        dict3 = Merge(reviewdict, reviewdict1)\n",
    "        \n",
    "\n",
    "        # Add the review to the review_data list\n",
    "        review_data.append(dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the review data to a JSON file\n",
    "with open('review_data.json', 'w') as f:\n",
    "    json.dump(review_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # Set the base URL for the review webpage\n",
    "# review_base_url = 'https://www.imdb.com/title/tt0111161/reviews'\n",
    "\n",
    "# # Set the URL for the \"Load more\" button\n",
    "# load_more_url = 'https://www.imdb.com/title/tt0111161/reviews/_ajax'\n",
    "\n",
    "# # Initialize an empty list to store the review data\n",
    "# review_data = []\n",
    "\n",
    "# # Set a flag to indicate whether there are more reviews to load\n",
    "# more_reviews = True\n",
    "\n",
    "# while more_reviews:\n",
    "#     # Make a request to the review webpage\n",
    "#     response = requests.get(review_base_url)\n",
    "\n",
    "#     # Parse the HTML content\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#     # Find all the review elements\n",
    "#     review_elements = soup.find_all(class_='review-container')\n",
    "\n",
    "#     # Loop through the review elements and extract the review data\n",
    "#     for element in review_elements:\n",
    "#         # Find the title of the review\n",
    "#         review_title = element.find(class_='title').text\n",
    "\n",
    "#         # Find the text of the review\n",
    "#         review_text = element.find(class_='text').text\n",
    "\n",
    "#         # Find the rating of the review\n",
    "#         review_rating = element.find(class_='rating').text\n",
    "\n",
    "#         # Find the user who wrote the review\n",
    "#         review_user = element.find(class_='display-name-link').text\n",
    "\n",
    "#         # Store the review data in a dictionary\n",
    "#         review = {\n",
    "#             'title': review_title,\n",
    "#             'text': review_text,\n",
    "#             'rating': review_rating,\n",
    "#             'user': review_user\n",
    "#         }\n",
    "\n",
    "#         # Add the review to the review_data list\n",
    "#         review_data.append(review)\n",
    "\n",
    "#     # Check if there are more reviews to load\n",
    "#     more_reviews_button = soup.find(class_='ipl-load-more__button')\n",
    "#     if more_reviews_button:\n",
    "#         # There are more reviews to load, simulate the \"Load more\" button request\n",
    "#         review_count = len(review_data)\n",
    "#         payload = {'paginationKey': more_reviews_button['data-key']}\n",
    "#         headers = {'referer': review_base_url}\n",
    "#         response = requests.post(load_more_url, data=payload, headers=headers)\n",
    "\n",
    "#         # Update the review webpage URL with the next page of reviews\n",
    "#         review_base_url = f'{review_base_url}?start={review_count}'\n",
    "#     else:\n",
    "#         # There are no more reviews to load, set the flag to False\n",
    "#         more_reviews = False\n",
    "\n",
    "# # Save the review data to a JSON file\n",
    "# with open('review_data.json', 'w') as f:\n",
    "#     json.dump(review_data,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
